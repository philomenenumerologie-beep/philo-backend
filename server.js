// server.js
// Backend PhilomÃ¨ne I.A.
// - /ask : conversation texte
// - /analyze-image : analyse d'image
// - /config : infos publiques paiement (PayPal)
// - mÃ©moire de conversation en RAM (simple)
// ------------------------------------------------------------

import express from "express";
import cors from "cors";
import fetch from "node-fetch";
import multer from "multer";

// (optionnel, utile en local)
try { await import("dotenv").then(m => m.default.config()); } catch {}

// ------------------------------------------------------------
// App & middlewares
// ------------------------------------------------------------
const app = express();
app.set("trust proxy", true);

// Limites dâ€™upload / JSON
app.use(express.json({ limit: "15mb" }));
app.use(express.urlencoded({ extended: true }));

// CORS : autorise ton site
const corsOpts = {
  origin: ["https://philomeneia.com", "https://www.philomeneia.com"],
  methods: ["POST", "GET", "OPTIONS"],
  allowedHeaders: ["Content-Type", "Authorization"],
};
app.use(cors(corsOpts));
app.options("*", cors(corsOpts));

// Multer pour les images
const upload = multer({
  storage: multer.memoryStorage(),
  limits: { fileSize: 10 * 1024 * 1024 }, // 10 MB
});

// ------------------------------------------------------------
// CONFIG ENV
// ------------------------------------------------------------
const {
  OPENAI_API_KEY = "",
  OPENAI_MODEL_TEXT = "gpt-4o-mini",
  OPENAI_MODEL_VISION = "gpt-4o",
  PAYMENT_ENABLED,
  PAYMENTS_ENABLED,
  PAYPAL_CLIENT_ID = "",
  PAYPAL_MODE = "sandbox",
} = process.env;

const envTrue = (v) => String(v ?? "").trim().toLowerCase() === "true";

if (!OPENAI_API_KEY) {
  console.warn("âš ï¸  OPENAI_API_KEY manquant. Mets-le dans Render â†’ Environment.");
}

// ------------------------------------------------------------
// MÃ‰MOIRE DE CONVERSATION (RAM)
// ------------------------------------------------------------
const conversations = {};

function getConversationHistory(userId) {
  if (!conversations[userId]) {
    conversations[userId] = [
      {
        role: "system",
        content:
          "Tu es PhilomÃ¨ne I.A., une assistante personnelle franÃ§aise. " +
          "RÃ©ponds clairement, simplement, sans blabla inutile. " +
          "Sois sympa et directe, avec des infos concrÃ¨tes.",
      },
    ];
  }
  return conversations[userId];
}

function pushToConversation(userId, role, content) {
  const history = getConversationHistory(userId);
  history.push({ role, content });
  const MAX_MESSAGES = 60;
  if (history.length > MAX_MESSAGES) {
    const systemMsg = history[0];
    const lastMsgs = history.slice(-MAX_MESSAGES + 1);
    conversations[userId] = [systemMsg, ...lastMsgs];
  }
}

// ------------------------------------------------------------
// APPELS OPENAI
// ------------------------------------------------------------
async function askOpenAIText(messages) {
  const body = { model: OPENAI_MODEL_TEXT, messages };

  try {
    // premier essai : modÃ¨le rapide (gpt-4o-mini)
    const resp = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${OPENAI_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify(body),
    });

    if (!resp.ok) throw new Error("Mini model failed");

    const data = await resp.json();
    const answer = data?.choices?.[0]?.message?.content?.trim();
    return answer || "Je n'ai pas pu gÃ©nÃ©rer de rÃ©ponse.";
  } catch {
    // fallback vers GPT-4o complet
    console.warn("âš ï¸ gpt-4o-mini indisponible, fallback vers gpt-4o");
    body.model = "gpt-4o";
    const retry = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${OPENAI_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify(body),
    });
    const data = await retry.json();
    return (
      data?.choices?.[0]?.message?.content?.trim() ||
      "RÃ©ponse gÃ©nÃ©rÃ©e avec le modÃ¨le complet."
    );
  }
}

async function askOpenAIVision({ question, dataUrl }) {
  const messages = [
    {
      role: "system",
      content:
        "Tu es PhilomÃ¨ne I.A., assistante franÃ§aise. Analyse l'image et explique clairement ce qu'il y a dessus. Si tu n'es pas sÃ»re, dis-le.",
    },
    {
      role: "user",
      content: [
        { type: "text", text: question || "Analyse l'image." },
        { type: "image_url", image_url: dataUrl },
      ],
    },
  ];
  const body = { model: OPENAI_MODEL_VISION, messages };

  const resp = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${OPENAI_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify(body),
  });

  if (!resp.ok) {
    const textErr = await resp.text();
    console.error("âŒ OpenAI /vision status:", resp.status);
    console.error("âŒ OpenAI /vision body:", textErr);
    throw new Error(`Erreur API OpenAI (vision) ${resp.status}`);
  }

  const data = await resp.json();
  const answer = data?.choices?.[0]?.message?.content?.trim();
  return answer || "Image reÃ§ue, mais impossible de l'analyser.";
}

// ------------------------------------------------------------
// ROUTES IA
// ------------------------------------------------------------
app.post("/ask", async (req, res) => {
  try {
    const { conversation, userId, tokens } = req.body || {};
    const uid = userId || "guest";

    let lastUserMessage = null;
    if (Array.isArray(conversation)) {
      for (let i = conversation.length - 1; i >= 0; i--) {
        const msg = conversation[i];
        if (msg.role === "user" && msg.content && msg.content.trim()) {
          lastUserMessage = msg.content.trim();
          break;
        }
      }
    }

    if (!lastUserMessage) {
      return res.status(400).json({ error: "Pas de message utilisateur reÃ§u." });
    }

    pushToConversation(uid, "user", lastUserMessage);
    const fullHistory = getConversationHistory(uid);

    const answer = await askOpenAIText(fullHistory);

    pushToConversation(uid, "assistant", answer);

    res.json({ answer, tokensLeft: tokens });
  } catch (err) {
    console.error("ğŸ”¥ Erreur /ask:", err);
    res.status(500).json({ error: "Erreur interne /ask." });
  }
});

app.post("/analyze-image", upload.single("image"), async (req, res) => {
  try {
    const uid = req.body?.userId || "guest";
    const userPrompt =
      req.body?.prompt || "DÃ©cris prÃ©cisÃ©ment l'image et Ã  quoi elle sert.";

    if (!req.file) return res.status(400).json({ error: "Aucune image reÃ§ue." });

    const mimeType = req.file.mimetype || "image/jpeg";
    const base64 = req.file.buffer.toString("base64");
    const dataUrl = `data:${mimeType};base64,${base64}`;

    pushToConversation(uid, "user", `${userPrompt} [image envoyÃ©e]`);

    const visionAnswer = await askOpenAIVision({ question: userPrompt, dataUrl });

    pushToConversation(uid, "assistant", visionAnswer);

    res.json({ answer: visionAnswer });
  } catch (err) {
    console.error("ğŸ”¥ Erreur /analyze-image:", err);
    res.status(500).json({ error: "Erreur interne /analyze-image." });
  }
});

// ------------------------------------------------------------
// CONFIG PUBLIQUE POUR LE FRONT (PayPal)
// ------------------------------------------------------------
app.get("/config", (_req, res) => {
  const paymentsEnabled = envTrue(PAYMENT_ENABLED) || envTrue(PAYMENTS_ENABLED);
  const paypalClientId = (PAYPAL_CLIENT_ID || "").trim().replace(/\s+/g, "");
  const mode = (PAYPAL_MODE || "sandbox").trim();

  res.set({
    "Cache-Control": "no-store, max-age=0",
    Pragma: "no-cache",
    Expires: "0",
  });

  res.json({ paymentsEnabled, paypalClientId, mode });
});

// ------------------------------------------------------------
// HEALTHCHECK
// ------------------------------------------------------------
app.get("/", (_req, res) => {
  res.send("âœ… API PhilomÃ¨ne I.A. en ligne (GPT-4o, mÃ©moire, tokens).");
});

// ------------------------------------------------------------
// LANCEMENT SERVEUR
// ------------------------------------------------------------
const PORT = process.env.PORT || 10000;
app.listen(PORT, () => {
  console.log("ğŸš€ PhilomÃ¨ne backend dÃ©marrÃ© sur le port " + PORT);
});
